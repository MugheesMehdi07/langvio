# Usage Guide

This guide provides examples and explanations for using Langvio for natural language visual analysis.

## Basic Usage

### Creating a Pipeline

The first step is to create a pipeline, which connects an LLM processor with a vision processor:

```python
from langvio import create_pipeline

# Create a pipeline with default settings
pipeline = create_pipeline()

# Or with a specific configuration file
pipeline = create_pipeline(config_path="path/to/config.yaml")

# Or with specific processors
pipeline = create_pipeline(llm_name="gpt-4", vision_name="yolo")
```

### Processing an Image

Once you have a pipeline, you can process an image with a natural language query:

```python
# Process an image
result = pipeline.process(
    query="What objects are in this image?",
    media_path="path/to/image.jpg"
)

# Display results
print(f"Explanation: {result['explanation']}")
print(f"Output path: {result['output_path']}")
```

The `result` dictionary contains:
- `explanation`: Text explanation generated by the LLM
- `output_path`: Path to the output image with detected objects
- `detections`: Detailed detection results
- `query_params`: Parsed parameters from the query
- And more...

## Query Types

Langvio supports various types of queries for different analysis tasks:

### Object Detection

Basic object detection queries identify what's in an image:

```python
query = "What objects are in this image?"
# or
query = "Identify all the objects in this image."
```

### Object Counting

Counting queries provide numerical results:

```python
query = "Count how many people are in this image."
# or
query = "How many cars and bicycles are there?"
```

### Attribute Detection

You can query for objects with specific attributes:

```python
query = "Find all red objects in this image."
# or
query = "Are there any large animals in this scene?"
```

### Spatial Relationships

Queries can analyze spatial relationships between objects:

```python
query = "Find any objects on the table."
# or
query = "Is there a person standing next to a car?"
```

### Verification Queries

Yes/no questions about the image content:

```python
query = "Is there a refrigerator in this kitchen?"
# or
query = "Are there any children in this image?"
```

### Combined Analysis

Complex queries that combine multiple analysis types:

```python
query = "Analyze this street scene. Count people and vehicles, identify their locations relative to each other, and note any distinctive colors."
```

## Advanced Usage

### Customizing the Pipeline

You can customize the pipeline by setting specific processors:

```python
# Create a pipeline
pipeline = create_pipeline()

# Set a specific LLM processor
pipeline.set_llm_processor("gpt-4")

# Set a specific vision processor
pipeline.set_vision_processor("yolo_large")
```

### Working with Configuration Files

Langvio supports YAML configuration files:

```python
from langvio.config import Config

# Load a configuration
config = Config("path/to/config.yaml")

# Create a pipeline with this configuration
pipeline = create_pipeline(config_path="path/to/config.yaml")
```

Example configuration file:

```yaml
llm:
  default: "gpt-4"
  models:
    gpt-4:
      model_name: "gpt-4-turbo"
      model_kwargs:
        temperature: 0.1

vision:
  default: "yolo"
  models:
    yolo:
      type: "yolo"
      model_path: "yolov11x.pt"
      confidence: 0.3

media:
  output_dir: "./custom_output"
  visualization:
    box_color: [0, 0, 255]
    text_color: [255, 255, 255]
    line_thickness: 3
```

### Accessing Detection Results

You can access detailed detection results for custom analysis:

```python
result = pipeline.process(query, image_path)

# Access raw detections (for images, frame key is "0")
detections = result["detections"]["0"]

# Count objects by type
object_counts = {}
for det in detections:
    label = det["label"]
    if label not in object_counts:
        object_counts[label] = 0
    object_counts[label] += 1

print("Object counts:", object_counts)

# Access object attributes
for det in detections:
    if "attributes" in det:
        print(f"{det['label']} attributes:", det["attributes"])
```

### Using the CLI

Langvio includes a command-line interface:

```bash
# Basic usage
langvio --query "What objects are in this image?" --media path/to/image.jpg

# With custom config
langvio --query "Count the people" --media path/to/image.jpg --config path/to/config.yaml

# Specifying output directory
langvio --query "Find red objects" --media path/to/image.jpg --output ./results

# List available models
langvio --list-models
```

## Example Solutions

### Image Captioning

```python
from langvio import create_pipeline

pipeline = create_pipeline()
result = pipeline.process("Describe this image in detail", "path/to/image.jpg")
print(result["explanation"])
```

### Object Search

```python
from langvio import create_pipeline

pipeline = create_pipeline()
result = pipeline.process("Find all instances of dogs in this image", "path/to/image.jpg")
print(result["explanation"])
```

### Scene Analysis

```python
from langvio import create_pipeline

pipeline = create_pipeline()
query = "Analyze the spatial arrangement of furniture in this room"
result = pipeline.process(query, "path/to/room_image.jpg")
print(result["explanation"])
```

## Common Patterns and Best Practices

### Be Specific in Queries

More specific queries yield better results:

```python
# Good: Specific question
query = "How many people are wearing red shirts in this image?"

# Less good: Too general
query = "What's in this image?"
```

### Set Appropriate Confidence Thresholds

Adjust confidence thresholds based on your needs:

```python
# In config.yaml
vision:
  default: "yolo"
  models:
    yolo:
      confidence: 0.25  # Lower for more detections, higher for more certainty
```

### Process Output Files

The processed output files are saved to the output directory and can be used for further analysis:

```python
import cv2

# Load the output image
output_image = cv2.imread(result["output_path"])

# Do something with the output...
```

### Handling API Keys

For security, use environment variables or .env files for API keys:

```python
# In .env file
OPENAI_API_KEY=your_key_here
GOOGLE_API_KEY=your_key_here

# Then in your code
from langvio import create_pipeline
# Keys are automatically loaded from .env
pipeline = create_pipeline()
```